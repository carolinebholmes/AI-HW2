For our pathfinding algorithm under certainty is the A* algorithm using the length of the minimal possible path given no obstables as our heuristic. A* is a variation of Dijkstra's, so it guaranteed to find the shortest path given that the heuristic is consistent. It can better performance than Dijkstra's, as the heuristic allows it to prioritize paths that are more likely to be the shortest. 

The data sets that have more impediments farther away from the start and closer to the goal are more likely to be ineffcient(especially dense impediments), because it is more likely to have to backtrack much farther to get a new path and start over. It is also more likely to misidentify a square in the uncertain grids, as the probability of getting a correct read at the beginning is less likely the closer you are to the goal.

To deal with uncertainty, we ping all the spots on the board a certain initial number of times, and then from there we look at which squares we are not certain enough about.  We define a decision threshold in terms of standard deviations of the distribution at that point. If the tile does not fall within the threshold for either X or O we ping-once-test-once until the results fall within our standards for a decision. Moving this decision threshold down (and therefore narrowing the acceptable range for a decision) increases how confident we are when making a decision about each tile, at the tradeoff of increasing the number of pings it is likely to take to get to that level of certainty. We have found through modulating both the initial number of pings before testing and the stringency of the test that what we need is a threshold of around 1.4 standard deviations and a number of initial tests just big enough to make that meaningful in most cases, we use around 150-170 pings per tile and get about 5000 pings on top of that in dynamically added pings for tiles that didn’t meet our standard within those pings.
